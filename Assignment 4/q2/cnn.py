# -*- coding: utf-8 -*-
"""valid_ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hF-WuHBjQx5a3iNjYzvjFXWDGFLYS9dG
"""

from google.colab import drive
drive.mount('/content/drive')
  
#path_clone = "drive/My Drive/projects"
#!cd path_clone

#!git clone https://github.com/pashu123/train_pickle
#!rm -r train_pickle

!ls
!unzip "/content/drive/My Drive/train_pickle.zip"

!ls
!unzip "/content/drive/My Drive/test_dataset_new.zip"

from google.colab import drive
drive.mount('/content/drive')

import gzip
import _pickle
import random
from keras.models import Sequential
from keras.layers import Dense, MaxPooling2D,Conv2D, Flatten,Dropout,LeakyReLU
import pandas as pd
import os
import numpy as np
from sklearn.utils import shuffle

!ls
!unzip "/content/drive/My Drive/validation_cnn_pickle.zip"

#!git clone https://github.com/pashu123/validation_pickle
#df = pd.read_csv('/content/drive/My Drive/rewards.csv',header=None,dtype='int')
#rewards = df.iloc[:,:].values
#rewards = rewards[:,1]
def get_vald_data():
  lst = sorted(os.listdir('/content/validation_cnn_pickle'))
  fold=fold = random.sample(lst,1)
  while(str(fold[0])==".git"):
    fold = random.sample(lst,1)
  with gzip.open('/content/validation_cnn_pickle/'+str(fold[0]),'rb') as file:
    val = _pickle.load(file)
  #val_y = val_x[1]
  val_x = []
  for i in val[0]:
    val_x.append(i/255)
  #m = val_y.shape
  #print(m)
  op = []
  for i in val[1]:
    if i==0:
      op.append([1,0])
    else:
      op.append([0,1])
  val_y = np.array(op)
  return np.array(val_x),val_y
  #strt = int((str(fold[0])))
  #val_dmy = rewards[strt:strt+siz[0]]
  #val_y = []
  #for i in val_dmy:
  #  if int(i):
  #    val_y.append(1)
  #    val_y.append(0)
  #  else:
  #    val_y.append(0)
  #    val_y.append(1)
  #val_y = np.array(val_y)
  #m = val_y.shape
  #val_y = val_y.reshape(int(m[0]/2),2)
  #return val_x,val_y



def get_train_data(i):
  global train_x,train_y
  lst = sorted(os.listdir('/content/train_pickle'))
  #fold = random.sample(lst,1)
  #while(str(fold[0])==".git"):
  #  fold = random.sample(lst,1)
  print(str(lst[i]))
  with gzip.open('/content/train_pickle/'+str(lst[i]),'rb') as file:
    arr = _pickle.load(file)
  mx = len(arr[0])
  #indx = random.sample(range(m),int(0.6*m))
  #train_x0 = [arr[0][i] for i in indx]
  #train_x0 = np.array(train_x0)
  train_x0 = np.array(arr[0])
  #op = [1,0]*int(0.6*m)
  op = [1,0]*mx
  op = np.array(op)
  m = op.shape
  train_y0 = op.reshape(int(m[0]/2),2)
  n = len(arr[1])
  #indx = random.sample(range(n),int(mx/2))
  #train_x1 = [arr[1][i] for i in indx]
  #train_x1 = np.array(train_x1)
  train_x1 = np.array(arr[1])
  #op = [0,1]*int(0.4*m)
  op = [0,1]*n
  op = np.array(op)
  m = op.shape
  train_y1 = op.reshape(int(m[0]/2),2)
  train_y0 = train_y0.reshape(-1,2)
  train_y1 = train_y1.reshape(-1,2)
  train_x = np.vstack((train_x0,train_x1))
  train_y = np.vstack((train_y0,train_y1))
  #train_x, train_y = shuffle(train_x,train_y,random_state=0)
  
  return train_x/255,train_y

model = Sequential()

#add model layers
model.add(Conv2D(32, kernel_size=(3,3),strides=(2,2),activation='relu', input_shape=(210,160,5)))
#model.add(Conv2D(64, kernel_size=3,strides=(2,2),activation='relu', input_shape=(210,160,5)))
#model.add(Conv2D(32, kernel_size=3,strides=(2,2),activation='relu', input_shape=(140,140,5)))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Conv2D(64, kernel_size=(3,3),strides=(2,2),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(2048, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='softmax'))
#compile model using accuracy to measure model performance
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

#from keras.callbacks import ModelCheckpoint

from keras.models import load_model
model = load_model('/content/drive/My Drive/my_model_250_drop_seq.h5')
#model = load_model('/content/drive/My Drive/my_model_crop350.h5')
#filepath = "saved-model-{epoch:02d}-{val_acc:.2f}.hdf5"
#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')
for epoch in range(250,499):
  train_x,train_y = get_train_data(epoch+1)
  #train_x = train_x[:,50:190,10:150,:]
  val_x,val_y = get_vald_data()
  #val_x = val_x[:,50:190,10:150,:]
  print(train_x.shape)
  model.fit(train_x, train_y, epochs=epoch+1,initial_epoch=epoch,validation_data=(val_x,val_y),shuffle=True,batch_size=50)
  #model.fit(train_x, train_y, epochs=epoch+1,initial_epoch=epoch,shuffle=True,batch_size=50)
  del train_x
  del train_y

!ls
model.save('/content/drive/My Drive/my_model_250_drop_seq.h5')

#!ls
import numpy as np
import pandas as pd
from PIL import Image
import os
import random
from sklearn.decomposition import PCA
from sklearn.metrics import confusion_matrix
import pickle
from itertools import combinations

def rgb2gray(rgb):
    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])


folder = 'test_dataset'
lst = sorted(os.listdir(folder))
cnt = 0
pred_y = []
for i in range(len(lst)):
    res = []
    ls = sorted(os.listdir(folder+'/'+lst[i]))
    l = len(ls)
    fold = folder+'/'+lst[i]
    #res = np.empty((210,160,1))
    res = []
    for j in range(len(ls)):
        if (ls[j].endswith('.csv')):
            continue
        else:
            im = Image.open(fold+'/'+ls[j])
            im_ar = np.array(im)
            im_ar = rgb2gray(im_ar)
            #res = np.vstack((res,im_ar/255))
            res.append(im_ar/255)
    res = np.array(res,dtype='float32')
    res = np.stack(res,axis=2)
    m,n,p = res.shape
    res = res.reshape((1,m,n,p))
    #res = res[:,50:190,10:150,:]
    print(i)
    #print(res.shape)
    #m,n = res.shape
    #x = np.empty((210,160))
    #for j in range(m):
    #    x = np.vstack((x,res[j,:]))
    #print(res.shape)
    pred_y.append(cnt)
    cnt = cnt+1
    m_pred = model.predict(res)
    m_pred = m_pred.tolist()
    m_pred = m_pred[0]
    pred = m_pred.index(max(m_pred))
    print(pred)
    pred_y.append(pred)

import csv

pred_y = np.array(pred_y)
pred_y=pred_y.reshape(-1,1)
m,n = pred_y.shape
pred_y = pred_y.reshape(int(m/2),2)

with open("submision_250_dropseqval.csv","w") as file:
  writer = csv.writer(file)
  writer.writerow(["id","Prediction"])
  np.savetxt(file,pred_y, delimiter=",",fmt="%i")
print("Save")
from google.colab import files
files.download('submision_250_dropseqval.csv')
print("Download")
#model.save('my_model_250.h5')
#files.download('my_model_250.h5')